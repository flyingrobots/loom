#!/usr/bin/env python3
import sys
import re
from pathlib import Path
from pylatexenc.latexencode import unicode_to_latex

def clean_content(text):
    # 1. Fix specific project macros/artifacts BEFORE generic encoding
    
    # Pandoc macro fix for CΩMPUTER
    text = text.replace(r'C\Omega{}MPUTER', r'\COmega')
    text = text.replace(r'C\Omega MPUTER', r'\COmega')
    
    # Remove Pandoc Footer (the \section and copyright stuff that pandoc adds from metadata)
    # We use a robust regex to kill the specific section pandoc generates
    text = re.sub(
        r'\\section\*?{.*?C.*?Omega.*?MPUTER.*?Rights Reserved\s*$', 
        '', 
        text, 
        flags=re.DOTALL | re.IGNORECASE
    )

    # 2. Use pylatexenc to handle Unicode -> LaTeX
    # unknown_char_policy='replace' ensures we don't crash on weird stuff
    # non_ascii_only=True keeps standard text readable
    text = unicode_to_latex(text, non_ascii_only=True, unknown_char_policy='replace')

    # 3. Post-processing fixes
    
    # pylatexenc might escape characters we want to keep as macros if they were already latex?
    # Actually, pandoc outputs LaTeX with some unicode. 
    # If pandoc output `\section{...}`, unicode_to_latex might escape the backslash.
    # WAIT. This script runs on .tex files generated by pandoc.
    # Pandoc generates valid LaTeX structure (sections, items) but might leave Unicode chars.
    # If we run unicode_to_latex on the WHOLE file, it will escape all the `\begin`, `\section` etc.
    # That destroys the document structure. 
    
    # CRITICAL: We cannot simply run unicode_to_latex on the whole file.
    # We only want to fix specific unicode characters that pandoc left behind.
    
    # Reverting strategy: 
    # We will use a manual map for the specific Greek/Math symbols that are breaking things,
    # because parsing the LaTeX structure to only encode text content is complex and error-prone.
    # BUT, the user specifically asked for `pylatexenc`.
    
    # Let's try to be smart. 
    # Ideally we iterate through the file and replace high-byte chars using pylatexenc's logic,
    # but strictly for non-ASCII characters. 
    
    def replace_non_ascii(match):
        char = match.group(0)
        # Use pylatexenc to convert just this character
        latex = unicode_to_latex(char, non_ascii_only=True)
        # Ensure it's wrapped in math mode if it's a math symbol
        # This is heuristic. pylatexenc often does \text... or \ensuremath
        return latex

    # Find all non-ascii characters
    text = re.sub(r'[^\x00-\x7F]', replace_non_ascii, text)

    # 4. specific overrides for our project consistency after generic conversion
    # pylatexenc might output \textOmega, but we might prefer \Omega or \ensuremath{\Omega}
    # Let's see what happens. For now, trust pylatexenc for the bulk. 
    
    # Fix double-escaped things if they occurred
    text = text.replace(r'\\textbullet{}', r'\textbullet{}')
    
    # Specific fix for the "There's no line here to end" error (double backslashes at paragraph end)
    text = re.sub(r'\\\\s*\n\s*\n', '\n\n', text)

    return text

def main():
    if len(sys.argv) > 1:
        target_dir = Path(sys.argv[1])
    else:
        print("Usage: python3 clean-unicode.py <directory>")
        sys.exit(1)

    if not target_dir.exists():
        print(f"Directory {target_dir} does not exist.")
        sys.exit(1)

    for tex_file in target_dir.glob('*.tex'):
        try:
            content = tex_file.read_text(encoding='utf-8', errors='replace')
            # We need to be careful not to double-process if this script runs multiple times
            # But we rely on the Makefile to control that.
            cleaned = clean_content(content)
            if content != cleaned:
                tex_file.write_text(cleaned, encoding='utf-8')
                print(f"  ✓ Cleaned {tex_file.name}")
        except Exception as e:
            print(f"  ✗ Error cleaning {tex_file.name}: {e}")

if __name__ == '__main__':
    main()
