# JIT RFC-0006

## Write-Ahead Log (WAL) Format & Replay Semantics (WFR v1.0)

Status: Draft**
Author: James Ross**
Contributors: JIT Community**
Requires:
	•	RFC-0001 Node Identity
	•	RFC-0002 DAG Invariants
	•	RFC-0003 Shadow Working Sets
	•	RFC-0004 Materialized Head
	•	RFC-0005 Inversion Engine
Start Date: 2025-11-28**
Target Spec: JITOS v0.x, TECHSPEC v0.3+
License: Open Source (TBD)**

⸻

1. Summary

This RFC defines:
	•	the canonical WAL binary format
	•	the rules for appending events
	•	the rules for replaying events
	•	the rules for crash recovery
	•	the ordering constraints on time
	•	the guarantees necessary for determinism

The WAL is the temporal substrate of JIT, encoding the arrow of time and ensuring the universe can be reconstructed exactly, on any machine, at any point in the future.

This is the system’s memory of becoming, as distinct from the DAG’s memory of being.

⸻

2. Motivation

Why WAL?
	•	JIT must survive crashes
	•	JIT must be fully deterministic
	•	JIT must replay nodes and indexes exactly
	•	JIT must restore Materialized Head
	•	JIT must restore SWS states
	•	JIT must recover after partial operations
	•	JIT must preserve ordering

In a causal universe:

WAL is time;
DAG is space-time geometry;
MH is perception.

WAL is the time-axis of the JIT kernel.

⸻

3. Requirements

The WAL MUST provide:

Append-Only Safety

Entries are appended atomically.

Durability

fsync required before confirming operations.

Total Ordering

Entries form a single linear timeline.

Determinism

Replay must regenerate identical state.

Crash Tolerance

Corrupted partial entries must be skipped or corrected via checksum.

Atomic Replay

Index state must be rebuilt atomically.

Isolation

No partially applied operations.

Cross-Platform Stability

Endianness, alignment, etc. must be canonical.

⸻

4. WAL Record Structure

Every WAL entry is binary:

WALRecord {
    magic: u32 = 0x4A495420  (# "JIT ")
    version: u16
    op_type: u16
    logical_ts: u64
    payload_len: u64
    payload: bytes[payload_len]
    checksum: blake3-256
}

Notes:
	•	magic identifies valid entries
	•	logical_ts MUST be Lamport timestamp
	•	payload MUST be canonical CBOR
	•	checksum MUST be of everything except itself
	•	if checksum fails → skip entry and continue

⸻

5. WAL Operation Types

5.1 WAL_OP_CREATE_NODE

Payload: canonical node encoding
Effect: append node to DAG

5.2 WAL_OP_UPDATE_INDEX

Payload: index delta
Effect: update LMDB indexes

5.3 WAL_OP_UPDATE_TREE_INDEX

Payload: per-file tree index updates
Effect: update MH tree indexing

5.4 WAL_OP_SWS_CREATE / DESTROY

Payload: SWS metadata
Effect: restore working sets

5.5 WAL_OP_SET_REF

Payload: {refname, new_target}
Effect: update reference pointers

5.6 WAL_OP_SYNC_EVENT

Payload: sync metadata
Effect: track remote sync states

Future expansions:
	•	WAL_OP_REWRITE_METADATA
	•	WAL_OP_COMPRESSION_CONTROL

⸻

6. WAL File Layout

WAL MUST be stored at:

.gitd/wal/log.wal

Rules:
	•	MUST NOT be deleted except by compaction
	•	MUST NOT be truncated without checkpoint
	•	MUST be read sequentially
	•	MUST be sync’d after each entry

⸻

7. Checkpointing

To avoid infinite WAL growth:
	•	system periodically writes a checkpoint, a snapshot of:
	•	index state
	•	tree-index state
	•	head references
	•	SWS metadata

Stored at:

.gitd/wal/checkpoint.cbor

During startup:
	1.	Read checkpoint
	2.	Apply WAL entries newer than checkpoint
	3.	Reconstruct everything deterministically

⸻

8. WAL Replay Procedure

Pseudo-code:

function replay_wal():
    state = load_checkpoint()
    for entry in wal:
        if checksum_invalid(entry): continue
        apply(entry, state)
    return state

This MUST result in:
	•	identical DAG
	•	identical indexes
	•	identical MH
	•	identical SWS metadata
	•	identical ref pointers

Replay is truth.
If replay changes behavior → invariants broken.

⸻

9. Atomicity Guarantees

Each WAL entry MUST commit atomically:
	•	write entry
	•	fsync
	•	return success

If crash occurs mid-entry:
	•	replay MUST detect partial data
	•	partial entries MUST be ignored
	•	prior entries MUST be intact

⸻

10. Interaction with Inversion Engine

During collapse:
	•	Inversion Engine writes multiple WAL entries
	•	MUST ensure atomic consideration
	•	MUST update logical timestamp
	•	MUST reflect rewrite nodes and snapshot nodes
	•	MUST append ref update LAST

WAL ensures that a collapse event is either:
	•	fully applied
	•	not applied at all

No in-between states allowed.

⸻

11. Interaction with SWS

SWS creation and destruction MUST log:
	•	SWS identity
	•	base node
	•	metadata

Upon crash:
	•	all SWS MUST be restored
	•	or invalid SWS MUST be marked and discarded

SWS replay is essential to restoring agent contexts for in-progress work.

⸻

12. WAL & Distributed Sync

During sync:
	•	remote nodes appended after validation
	•	remote ref updates logged
	•	WAL ensures sync is replayable
	•	ensures cross-machine consistency

The WAL is the causal ordering mechanism across distributed systems.

⸻

13. Security Considerations
	•	strict verification of checksums
	•	protect against corrupted WAL entries
	•	enforce replay signatures
	•	SWS replay must validate agent IDs
	•	DST (Distributed Sync Trust) model TBD

⸻

14. Why WAL Is Foundational

Without WAL:
	•	DAG cannot be reconstructed
	•	MH cannot be recovered
	•	SWS cannot be restored
	•	distributed correctness collapses
	•	crash safety disappears
	•	determinism fails

WAL is literally the time-axis of the JIT universe.

The DAG is the geometry.
The WAL is the temporal ordering of becoming.

⸻

15. Status & Next Steps

Next RFC:

[RFC-0007](./RFC-0007.md) — JIT RPC API (The Syscall Layer of the Post-File OS)

---

# **CΩMPUTER • JITOS** 
© 2025 James Ross • [Flying • Robots](https://flyingrobots.dev)
All Rights Reserved

